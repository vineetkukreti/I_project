{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "jW2Uk8otQvi8",
        "outputId": "08f2d715-7e92-4ea5-d85c-2b97e0cf9f2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vinee\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vinee\\anaconda3\\lib\\site-packages)\n",
            "ERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0)\n",
            "ERROR: No matching distribution found for tensorflow==2.0.0\n",
            "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vinee\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vinee\\anaconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vinee\\anaconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# !!pip uninstall tensorflow\n",
        "# !pip install tensorflow==2.0.0\n",
        "# pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9kv9tyJ77eF"
      },
      "source": [
        "## Get Required Files from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0O_n6OIEVyL",
        "outputId": "7e9b015c-dd47-416f-ee0d-2c500e596c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mgRpOvFMjKR"
      },
      "outputs": [],
      "source": [
        "#Set your project path\n",
        "project_path =  '/content/drive/My Drive'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXYwajPeQbRq"
      },
      "source": [
        "#**## Reading and Exploring Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAk6BRUh8CqL"
      },
      "source": [
        "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data.\n",
        "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StSLB-T8PuGr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data = pd.read_json(os.path.join(project_path,'Sarcasm_Headlines_Dataset.json'),lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m6LXx4qHqgWN",
        "outputId": "f53f73c8-4085-4017-9279-dc709e5ed4fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            article_link  \\\n",
              "0      https://www.huffingtonpost.com/entry/versace-b...   \n",
              "1      https://www.huffingtonpost.com/entry/roseanne-...   \n",
              "2      https://local.theonion.com/mom-starting-to-fea...   \n",
              "3      https://politics.theonion.com/boehner-just-wan...   \n",
              "4      https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
              "...                                                  ...   \n",
              "26704  https://www.huffingtonpost.com/entry/american-...   \n",
              "26705  https://www.huffingtonpost.com/entry/americas-...   \n",
              "26706  https://www.huffingtonpost.com/entry/reparatio...   \n",
              "26707  https://www.huffingtonpost.com/entry/israeli-b...   \n",
              "26708  https://www.huffingtonpost.com/entry/gourmet-g...   \n",
              "\n",
              "                                                headline  is_sarcastic  \n",
              "0      former versace store clerk sues over secret 'b...             0  \n",
              "1      the 'roseanne' revival catches up to our thorn...             0  \n",
              "2      mom starting to fear son's web series closest ...             1  \n",
              "3      boehner just wants wife to listen, not come up...             1  \n",
              "4      j.k. rowling wishes snape happy birthday in th...             0  \n",
              "...                                                  ...           ...  \n",
              "26704               american politics in moral free-fall             0  \n",
              "26705                            america's best 20 hikes             0  \n",
              "26706                              reparations and obama             0  \n",
              "26707  israeli ban targeting boycott supporters raise...             0  \n",
              "26708                  gourmet gifts for the foodie 2014             0  \n",
              "\n",
              "[26709 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef5a4f00-6a01-4c5e-835e-074217168cb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26704</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/american-...</td>\n",
              "      <td>american politics in moral free-fall</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26705</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/americas-...</td>\n",
              "      <td>america's best 20 hikes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26706</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/reparatio...</td>\n",
              "      <td>reparations and obama</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26707</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/israeli-b...</td>\n",
              "      <td>israeli ban targeting boycott supporters raise...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26708</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/gourmet-g...</td>\n",
              "      <td>gourmet gifts for the foodie 2014</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26709 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef5a4f00-6a01-4c5e-835e-074217168cb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef5a4f00-6a01-4c5e-835e-074217168cb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef5a4f00-6a01-4c5e-835e-074217168cb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0f01e73-edc1-408e-989d-e0407263d3be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0f01e73-edc1-408e-989d-e0407263d3be')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0f01e73-edc1-408e-989d-e0407263d3be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "wsNtC1fDqnH_",
        "outputId": "b672159b-d24f-438d-d0d1-90e999c08c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26709, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       is_sarcastic\n",
              "count  26709.000000\n",
              "mean       0.438953\n",
              "std        0.496269\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2071a4e7-9bf2-49b9-87db-e3e8cfab64e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26709.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.438953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2071a4e7-9bf2-49b9-87db-e3e8cfab64e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2071a4e7-9bf2-49b9-87db-e3e8cfab64e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2071a4e7-9bf2-49b9-87db-e3e8cfab64e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1aca8ef-01a6-4d07-b9e0-0b235c7be5ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1aca8ef-01a6-4d07-b9e0-0b235c7be5ad')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1aca8ef-01a6-4d07-b9e0-0b235c7be5ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print (data.shape)\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tNpztCllqwJT",
        "outputId": "35648a0a-4077-459d-c4a1-f8a37936fdb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the 'roseanne' revival catches up to our thorny political mood, for better and worse\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data['headline'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxLSk1n9rFL2",
        "outputId": "621bc824-62dc-436b-f951-430b09f5a6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "##The column headline needs to be cleaned up as we have special characters and numbers in the column\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "def cleanData(text):\n",
        "  text = re.sub(r'\\d+', '', text)\n",
        "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "  return text\n",
        "\n",
        "data['headline']=data['headline'].apply(cleanData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e_FfMsSr3W73",
        "outputId": "6633632d-f66d-48ef-f887-6c012dcc1153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the roseanne revival catches up to our thorny political mood for better and worse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data['headline'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6pXf7A78E2H"
      },
      "source": [
        "## Drop `article_link` from dataset.\n",
        "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLSVsvrlP9qD"
      },
      "outputs": [],
      "source": [
        "data.drop('article_link',inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0h6IOxU8OdH"
      },
      "source": [
        "## Get the Length of each line and find the maximum length.\n",
        "As different lines are of different length. We need to pad the our sequences using the max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRAsChZAQmr3"
      },
      "outputs": [],
      "source": [
        "maxlen = max([len(text) for text in data['headline']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPPd0YuPXi2M"
      },
      "source": [
        "#**## Modelling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35abKfRx8as3"
      },
      "source": [
        "## Import required modules required for modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVel73hYEV4r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ziybaD1RdD9"
      },
      "source": [
        "# Set Different Parameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPw9gAN_EV6m"
      },
      "outputs": [],
      "source": [
        "max_features = 10000\n",
        "maxlen = max([len(text) for text in data['headline']])\n",
        "embedding_size = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abSe-bM8fn9"
      },
      "source": [
        "## Apply Keras Tokenizer of headline column of your data.\n",
        "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features)\n",
        "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9Ad26HfTFMS"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_features,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts(data['headline'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ffi63KsST3P"
      },
      "source": [
        "# Define X and y for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnjxBdqmSS4s",
        "outputId": "6339f268-5b0f-4a90-87a1-b69d46704c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Samples: 26709\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0  287  780 3505 2213   47  353   92 2111    5\n",
            " 2476 8139]\n",
            "Number of Labels:  26709\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "X = tokenizer.texts_to_sequences(data['headline'])\n",
        "X = pad_sequences(X, maxlen = maxlen)\n",
        "y = np.asarray(data['is_sarcastic'])\n",
        "\n",
        "print(\"Number of Samples:\", len(X))\n",
        "print(X[0])\n",
        "print(\"Number of Labels: \", len(y))\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJLyKg-98rH_"
      },
      "source": [
        "## Get the Vocabulary size\n",
        "You can use tokenizer.word_index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-2w0gHEUUIo",
        "outputId": "e6069db9-6fa9-4622-8e5e-6456eca763a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27667\n"
          ]
        }
      ],
      "source": [
        "num_words=len(tokenizer.word_index)\n",
        "print (num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hjeMi40XcB1"
      },
      "source": [
        "#**## Word Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUF1TuQa8ux0"
      },
      "source": [
        "## Get Glove Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq5AIfRtMeZh"
      },
      "outputs": [],
      "source": [
        "glove_file = project_path + \"glove.6B.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXRBvtIKZCJc",
        "outputId": "cb194014-245d-4b0f-be37-cf015d666071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = '/content/drive/My Drive/glove.6B.zip'"
      ],
      "metadata": {
        "id": "3iSIgnJIZMS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJLX_n2WMecA"
      },
      "outputs": [],
      "source": [
        "#Extract Glove embedding zip file\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(glove_file, 'r') as z:\n",
        "  z.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Word Embeddings using Embedding file as given below.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1q-wxRsYx1o",
        "outputId": "e539eec9-f618-4901-ea86-5690d99c3cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elZ-T5aFGZmZ",
        "outputId": "6ced9c7d-98a0-4c4c-8f80-eda268a30fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Load word embeddings from the GloVe file\n",
        "embedding_file = './glove.6B.200d.txt'\n",
        "embeddings = {}\n",
        "with open(embedding_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype='float32')\n",
        "        embeddings[word] = vector\n",
        "\n",
        "# Calculate num_words based on tokenizer\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Initialize embedding_matrix\n",
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Check the length of embeddings.values()\n",
        "len(embeddings.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTPxveDmVCrA"
      },
      "source": [
        "# Create a weight matrix for words in training docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQgOhiywU9nU",
        "outputId": "4932b097-60a6-416f-f59f-0e59718020e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "len(embeddings.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IbWuEX82Ra"
      },
      "source": [
        "## Create and Compile your Model\n",
        "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required.\n",
        "In the end add a final dense layer with sigmoid activation for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7jhsSgYXG4l"
      },
      "outputs": [],
      "source": [
        "### Embedding layer for hint\n",
        "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
        "### Bidirectional LSTM layer for hint\n",
        "## model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype=tf.int64)\n",
        "embed = Embedding(embedding_matrix.shape[0],output_dim=200,weights=[embedding_matrix],input_length=maxlen, trainable=True)(input_layer)\n",
        "lstm=Bidirectional(LSTM(128))(embed)\n",
        "drop=Dropout(0.3)(lstm)\n",
        "dense =Dense(100,activation='relu')(drop)\n",
        "out=Dense(2,activation='softmax')(dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJFMxZwMWoTw"
      },
      "source": [
        "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpVkajCcWnRK",
        "outputId": "9262b2a1-23b8-465b-cc82-9fcb7cbc1235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 240)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 240, 200)          5533600   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               336896    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               25700     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5896398 (22.49 MB)\n",
            "Trainable params: 5896398 (22.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "model = Model(input_layer,out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNDkfYCWte4Q",
        "outputId": "976b7633-f86d-46a6-f6ed-18722e5bb356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "214/214 [==============================] - 38s 128ms/step - loss: 0.4540 - accuracy: 0.7780\n",
            "Epoch 2/5\n",
            "214/214 [==============================] - 13s 58ms/step - loss: 0.2648 - accuracy: 0.8913\n",
            "Epoch 3/5\n",
            "214/214 [==============================] - 9s 43ms/step - loss: 0.1764 - accuracy: 0.9301\n",
            "Epoch 4/5\n",
            "214/214 [==============================] - 8s 38ms/step - loss: 0.1142 - accuracy: 0.9583\n",
            "Epoch 5/5\n",
            "214/214 [==============================] - 9s 41ms/step - loss: 0.0725 - accuracy: 0.9750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d6b1c120070>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "model.fit(X_train,y_train,batch_size=batch_size, epochs=epochs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqvqFFu7tjqH",
        "outputId": "7d895b7f-e99e-45eb-b404-2425bc70141f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 3s 10ms/step\n"
          ]
        }
      ],
      "source": [
        "test_pred = model.predict(np.array(X_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkgjPw-ctohS"
      },
      "outputs": [],
      "source": [
        "test_pred = [1 if j>i else 0 for i,j in test_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "683aglhutqwx",
        "outputId": "3f7529d9-2581-4321-c40f-594a0e8b308e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2706,  325],\n",
              "       [ 398, 1913]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNjr1BQBtxGe",
        "outputId": "4ea1574d-feec-4fa7-9aa8-fe84631dbe26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      3031\n",
            "           1       0.85      0.83      0.84      2311\n",
            "\n",
            "    accuracy                           0.86      5342\n",
            "   macro avg       0.86      0.86      0.86      5342\n",
            "weighted avg       0.86      0.86      0.86      5342\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssLxdHIGt6Nl",
        "outputId": "a9e42982-8995-457f-db4c-ad9d71604979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as sarcasm_detection_model.pickle\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to a file\n",
        "with open('sarcasm_detection_model.pickle', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "print(\"Model saved as sarcasm_detection_model.pickle\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the saved model\n",
        "with open('sarcasm_detection_model.pickle', 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "\n",
        "# Input text for prediction\n",
        "input_text = \"the fascinating case for eating lab-grown meat\"\n",
        "# input_text = \"Miracle cure kills fifth patient\"\n",
        "# Preprocess the input text (cleaning and tokenization)\n",
        "def clean_text(text):\n",
        "    # Perform the same text cleaning as done during training\n",
        "    # For example, remove special characters, numbers, and apply lowercase\n",
        "    # You can reuse the cleanData function or write a similar one here\n",
        "    cleaned_text = cleanData(text)  # Assuming cleanData is defined in your code\n",
        "    return cleaned_text\n",
        "\n",
        "input_text = clean_text(input_text)\n",
        "\n",
        "# Tokenize the input text\n",
        "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "\n",
        "# Pad the input sequence to match the model's input shape\n",
        "input_sequence = pad_sequences(input_sequence, maxlen=maxlen)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = loaded_model.predict(input_sequence)\n",
        "\n",
        "# Assuming the model is a binary classifier, you can interpret the predictions like this:\n",
        "# If predictions[0][0] > predictions[0][1], it's not sarcastic\n",
        "# If predictions[0][0] <= predictions[0][1], it's sarcastic\n",
        "\n",
        "if predictions[0][0] > predictions[0][1]:\n",
        "    print(\"The news headline is sarcastic.\")\n",
        "else:\n",
        "    print(\"The news headline is not sarcastic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7sDi1cDbhcZ",
        "outputId": "808da12a-06b7-4d40-a084-22c4ed8b2d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 172 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d6b1070fd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Not sarcastic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Here i am also using chatgpt for"
      ],
      "metadata": {
        "id": "_OR5UgJtcLxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bm5V8CP_eJtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf71ffb-0407-4106-dc8d-7cae603e1130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "xQi2X_jcg7RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mom Warns Son to â€˜Watch Out for Idiots,â€™ Rearâ€‘Ends His Motorcycle."
      ],
      "metadata": {
        "id": "3SmQx_1DhNpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "api_key = \"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\"\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "news_headline = input_text\n",
        "\n",
        "\n",
        "prompt = f\"Is the following news headline sarcastic? \\n'{news_headline}'\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",  # You can choose a different engine if needed\n",
        "    prompt=prompt,\n",
        "    max_tokens=1,  # You can adjust the max_tokens to limit the response length\n",
        ")\n",
        "\n",
        "\n",
        "is_sarcastic = response.choices[0].text.strip()\n",
        "\n",
        "\n",
        "if is_sarcastic == \"Yes\":\n",
        "    print(\"The news headline is sarcastic.\")\n",
        "else:\n",
        "    print(\"The news headline is not sarcastic.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPq_EtLGd5CP",
        "outputId": "c160afa7-9c70-4579-d621-fe20bc77dd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The news headline is not sarcastic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVsrZg4-eHqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}